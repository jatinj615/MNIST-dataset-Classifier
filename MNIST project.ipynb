{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improrting MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  9.,  9.,  9.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   5,  89, 156, 231, 255, 163,  18,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  35, 165, 253, 253, 253, 254, 253,  78,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  43, 153, 224, 253, 253, 180, 174, 254, 253,  78,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   4,  70, 237, 253, 207,  71,  19,   2,   0, 254, 253,\n",
       "        78,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  23, 147, 253, 253, 177,  23,   0,   0,   0,   0,\n",
       "       254, 253,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  61, 217, 254, 254, 131,   0,   0,   0,   0,\n",
       "         0,  83, 255, 254, 101,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  87, 229, 254, 251, 135,   3,   0,   0,\n",
       "         0,  44, 132, 244, 254, 253, 129,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  85, 247, 253, 235, 124,   0,   0,\n",
       "         0,   0, 112, 229, 253, 253, 254, 253,  78,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 175, 253, 253, 120,   0,\n",
       "         0,  52, 212, 235, 250, 253, 253, 253, 254, 167,   6,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 235, 253, 253,\n",
       "       240, 195, 195, 248, 253, 254, 253, 253, 253, 253, 231,  24,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20, 254,\n",
       "       254, 254, 255, 254, 254, 222, 120,  38,   5, 156, 254, 254,  38,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         3, 136, 233, 241, 241, 225, 135,  25,   0,   0, 103, 253, 253,\n",
       "       207,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  30,  30,   0,   0,   0,   0,  19, 196,\n",
       "       253, 240,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       112, 253, 253, 146,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0, 231, 253, 222,  12,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0, 158, 255, 254, 152,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   4, 199, 254, 236,  42,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  70, 253, 254, 135,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0, 227, 253, 207,  25,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 159, 253,  60,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[69999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[69999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvxAUIQfCIrwA0ERfiAowg8ERfiBoP4f86Nc3LPrs6MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4efc742978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = X[1000]\n",
    "_image = _.reshape(28,28)\n",
    "plt.imshow(_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find number 4 and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24754, 24755, 24756, ..., 65136, 65137, 65138]),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y==4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[24754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\no7VzBnoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4ef49330b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = X[24759]\n",
    "_image = _.reshape(28, 28)\n",
    "plt.imshow(_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_split = 60000\n",
    "X_train, X_test, y_train, y_test = X[:num_split], X[num_split:], y[:num_split], y[num_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(num_split)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_0 = (y_train == 0)\n",
    "y_train_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_0 = (y_test == 0)\n",
    "y_test_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jatin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=0, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(random_state = 0)\n",
    "clf.fit(X_train, y_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97619999999999996"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_0, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Calculating Accuracy Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score\n",
    "clf = SGDClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skfolds = StratifiedKFold(n_splits=3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jatin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979451027449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jatin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jatin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98789939497\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skfolds.split(X_train, y_train_0):\n",
    "    clone_clf = clone(clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_0[train_index]\n",
    "    X_test_folds = X_train[test_index]\n",
    "    y_test_folds = y_train_0[test_index]\n",
    "    \n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_folds)\n",
    "    n_correct = sum(y_pred == y_test_folds)\n",
    "    print (n_correct/ len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation score using K-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jatin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jatin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/home/jatin/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.97945103,  0.94005   ,  0.98789939])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X_train, y_train_0, cv=3, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
